# v1 训练日志分析

## 训练配置

```
============================================================
Training Configuration Summary
============================================================
Model path: /data/huggingface_cache/hub/models--Tongyi-MAI--MAI-UI-2B/snapshots/503050934809558c8dfd2ddedaf9621fa74ac2de/
Data path: /data/codes/mai-ui-trainer/dataset/processed/sft_train.jsonl
Output directory: /data/codes/mai-ui-trainer/trainer/configs/models/sft_model
Max length: 1024
Use LoRA: True
  LoRA r: 16
  LoRA alpha: 32
  LoRA dropout: 0.05
  LoRA target modules: ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj']
Use 4-bit quantization: False
Gradient checkpointing: True
============================================================
```

## 训练结果

```
trainable params: 17,432,576 || all params: 2,144,964,608 || trainable%: 0.8127
Dataset size: 26 samples
Total steps: 6
Training time: 133.21s (约 2分13秒)
Speed: 22.20s/it
Final loss: 2.6357
```

## 为什么 v1 这么快？

### 核心原因：**纯文本训练，忽略图像**

v1 版本的 `sft_trainer_v1.py` 在处理多模态数据时，**完全忽略了图像内容**：

```python
# sft_trainer_v1.py 第 229-232 行
elif item.get("type") == "image_url":
    # For vision models, image URLs are handled separately
    # Here we just note that an image is present
    text_parts.append("[IMAGE]")  # ← 图像被替换为文本占位符！
```

### 数据流对比

| 步骤 | v1（纯文本） | v2（多模态） |
|------|------------|-------------|
| 1. 数据加载 | HuggingFace datasets | 手动 JSON 加载 |
| 2. 图像处理 | ❌ 用 `[IMAGE]` 占位符 | ✅ Base64 解码 → PIL Image |
| 3. Tokenize | `datasets.map()` 预处理 | 实时 processor 处理 |
| 4. Collator | `DataCollatorForLanguageModeling` | `MultiModalDataCollator` |
| 5. 前向传播 | 只有 LLM 文本处理 | LLM + 视觉编码器 |

### 性能影响

| 指标 | v1 | v2 |
|------|----|----|
| 每步时间 | ~22s | ~数分钟（或卡住） |
| 显存占用 | ~14GB | ~30GB+ |
| 图像信息 | ❌ 丢失 | ✅ 保留 |

## v1 的局限性

虽然 v1 训练快，但有重大缺陷：

1. **不学习视觉理解**：模型看不到实际的屏幕截图
2. **无法学习 grounding**：无法学习"点击哪个位置"的视觉对应关系
3. **仅学习文本模式**：只学到了指令→动作的文本映射

## 适用场景

- ✅ **快速验证**：验证训练流程是否正确
- ✅ **文本任务**：如果任务不依赖视觉（纯文本指令）
- ❌ **GUI Agent**：不适合，因为 GUI 任务需要理解屏幕内容

## 原始日志

```
`torch_dtype` is deprecated! Use `dtype` instead!
Info: /data/huggingface_cache/hub/models--Tongyi-MAI--MAI-UI-2B/snapshots/503050934809558c8dfd2ddedaf9621fa74ac2de/ appears to be a vision-language model. Trying Qwen3VLForConditionalGeneration or AutoModel...
`torch_dtype` is deprecated! Use `dtype` instead!
The module name  (originally ) is not a valid Python identifier. Please rename the original module to avoid import issues.
Gradient checkpointing enabled
trainable params: 17,432,576 || all params: 2,144,964,608 || trainable%: 0.8127
LoRA applied successfully
Dataset columns: ['messages', 'metadata']
Dataset size: 26
Sample keys: ['messages', 'metadata']
  messages: list with 3 items
    First item type: <class 'dict'>
  metadata: <class 'dict'>

Map: 100%|█████████████████████████████████████████████████████| 26/26 [00:00<00:00, 139.94 examples/s]
/data/codes/mai-ui-trainer/trainer/sft_trainer.py:691: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
The model is already on multiple devices. Skipping the move to device specified in `args`.
Starting SFT training...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.
  0%|                                                                            | 0/6 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
/data/anaconda3/envs/mai_ui/lib/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
{'train_runtime': 133.2071, 'train_samples_per_second': 0.586, 'train_steps_per_second': 0.045, 'train_loss': 2.6357380549112954, 'epoch': 3.0}
100%|████████████████████████████████████████████████████████████████████| 6/6 [02:13<00:00, 22.20s/it]
LoRA weights saved to /data/codes/mai-ui-trainer/trainer/configs/models/sft_model
SFT training completed. Output saved to /data/codes/mai-ui-trainer/trainer/configs/models/sft_model
```
